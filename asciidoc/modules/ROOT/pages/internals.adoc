= Internals[[internals-internals]]
:source-highlighter: rouge

On this page we describe some of the internals, and how easykube differs from a plain Kind instance.

== Local image registry

The registry is your local image cache. When operating a kind-cluster, it's possible to bootstrap an application by directly pushing images into the control plane - Easykube maintains a local registry. This is a trade-off between time  and diskspace.

After `easykube create`, `docker ps` reveals a
container named `registry:2` - This container survives `easykube destroy` and `easykube create` commands.

`easykube stop` will stop the registry and kind-control plane.

`easykube start` will attempt to start the registry and kind-control plane.

Whenever your easykube cluster is recreated, there is no need to pull images from the internet. By default your addons should pull from the local registry. You will see this pattern repeated across all addons.

Normally, an image is pulled from the internet, re-tagged, and pushed to the local registry.

Deployments will pull from the registry: *registry.localtest.me:5001* - Do explore how addons scripts retags, and patch deployments to use local images.

A common naming convention is used for images in deployments;

`registry.localtest.me:5001/myimage:x`

If Easykube should to pull images directly from private registries, an ImagePullSecret must be manually created, and your deployments amended to use this pull secret.

The registry is configured to use HTTPS, this is because Podman refuses to use insecure registries. To make SSL errors go away generate new certificates, or install the `localtest.me.ca.crt` found in `~/.config/easykube` to your trust store.

== DNS Resolution[[internals-dns]]

It might seem strange that everything is available at *.localtest.me â€” this is because someone on the internet was kind enough to create a public loopback domain. All DNS requests to localtest.me and any subdomain will resolve to 127.0.0.1.

Easykube takes advantage of this by configuring ingresses to use this hostname. If you are familiar with Apache httpd or another web server, it is fair to say that virtual hosts are generated dynamically whenever a new ingress definition is discovered by Kubernetes.

In the past, we would have had to manually create a virtual host and add an entry in our hosts file.

Sometimes services inside easykube need to resolve names like something.localtest.me. This won't work because 127.0.0.1 does not point to any https://kubernetes.io/docs/concepts/services-networking/service/#type-clusterip[ClusterIP].

We can get around this by emulating something called split-DNS. Depending on which network you originate from, a different IP address is resolved.

When easykube is created, the Kubernetes CoreDNS service is patched to intercept addresses from *.localtest.me. Below is an excerpt from the CoreDNS config that accomplishes this:

[source,text]
rewrite stop {
name regex (.*).localtest.me {1}-ext.default.svc.cluster.local
answer auto
}

NOTE: Currently, ext services can only reside in the default namespace.
The patch will translate foo.localtest.me into ext-foo.default.svc.cluster.local. So if you create a ClusterIP service with that name, requests originating from within the cluster will resolve to the ClusterIP. External requests will hit the ingress as usual.

TIP: Use ext services to emulate services that need to communicate in a transparent way. For example, when testing a CI workflow setup with a Git server (Gitea) and a Jenkins instance, Gitea will define an ext-* ClusterIP service, and Jenkins can then refer to the server with just gitea.localtest.me instead of gitea.default.svc.cluster.local.
